

############# Script 1 #############
 

ubuntu@DolfinED:~$ vim backup-script.sh
---
#!/bin/bash

time=$(date +%m-%d-%y_%H_%M_%S)
Backup_file=$1
Dest=/home/ubuntu/backup
filename=file-backup-$time.tar.gz
LOG_FILE="/home/ubuntu/backup/logfile.log"

if [ -z "$Backup_file"  ]
then
    echo "Please, Enter the directory that you want to backup " | tee -a "$LOG_FILE"
    exit 2
fi

if [ $? -ne 2 ]
  then
  if [ -f $filename ]
  then
      echo "Error file $filename already exists!" | tee -a "$LOG_FILE"
  else
      tar -czvf "$Dest/$filename" "$Backup_file" 
      echo "Backup completed successfully. Backup file: $Dest/$filename " | tee -a "$LOG_FILE"
  fi
fi
---




##################################################################################
##### Let's Do it with Automatically and upload the backup fril to Amazon S3 #####
##################################################################################


- Create a user (s3-bash-user) with the Permission policy "AmazonS3FullAccess"
- Create an IAM role (s3-bash-role) with the Permission policy "AmazonS3FullAccess" and "AmazonSSMFullAccess"
- Attach the IAM role to the EC2 instance


ubuntu@DolfinED:~$ mkdir aws-cli

ubuntu@DolfinED:~$ cd aws-cli/

ubuntu@DolfinED:~/aws-cli$ curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 55.8M  100 55.8M    0     0   131M      0 --:--:-- --:--:-- --:--:--  131M

ubuntu@DolfinED:~/aws-cli$ sudo apt install unzip

ubuntu@DolfinED:~/aws-cli$ unzip awscliv2.zip

ubuntu@DolfinED:~/aws-cli$ sudo ./aws/install
You can now run: /usr/local/bin/aws --version

ubuntu@DolfinED:~/aws-cli$ aws --version
aws-cli/2.13.19 Python/3.11.5 Linux/5.15.0-1044-aws exe/x86_64.ubuntu.20 prompt/off

ubuntu@DolfinED:~$ aws configure
AWS Access Key ID [None]: AK***********
AWS Secret Access Key [None]: Wi************
Default region name [None]: us-east-1
Default output format [None]: json

# Create an S3 bucket in AWS
ubuntu@DolfinED:~$ aws s3api create-bucket --bucket s3-new-bash-course --region us-east-1
{
    "Location": "/s3-new-bash-course"
}




############# Script 2 #############

ubuntu@DolfinED:~$ vim backup-script.sh
---
#!/bin/bash

time=$(date +%m-%d-%y_%H_%M_%S)
Backup_file=/home/ubuntu/bash
Dest=/home/ubuntu/backup
filename=file-backup-$time.tar.gz
LOG_FILE="/home/ubuntu/backup/logfile.log"

S3_BUCKET="s3-new-bash-course"
FILE_TO_UPLOAD="$Dest/$filename"


if ! command -v aws &> /dev/null; then
  echo "AWS CLI is not installed. Please install it first."
  exit 2
fi

if [ $? -ne 2 ]
  then
  if [ -f $filename ]
  then
      echo "Error file $filename already exist!" | tee -a "$LOG_FILE"
  else
      tar -czvf "$Dest/$filename" "$Backup_file" 
      echo "Backup completed successfully. Backup file: $Dest/$filename " | tee -a "$LOG_FILE"
      echo
      aws s3 cp "$FILE_TO_UPLOAD" "s3://$S3_BUCKET/"
  fi
fi

if [ $? -eq 0 ]; then
  echo
  echo "File uploaded successfully to the S3 bucket: $S3_BUCKET"
else
  echo "File upload to S3 failed."
fi
---





######## Now, let's automated it  #######

ubuntu@DolfinED:~$ sudo vim /etc/crontab
*/2 * * * * root /home/ubuntu/backup-script.sh

## check the aws
# Every 2 mins, we will take a backup and upload it to S3



## Delete the schedule
ubuntu@DolfinED:~$ sudo vim /etc/crontab


ubuntu@DolfinED:~$ aws s3 rb s3://s3-new-bash-course --force
delete: s3://s3-new-bash-course/file-backup-09-18-23_16_40_01.tar.gz
delete: s3://s3-new-bash-course/file-backup-09-18-23_15_22_20.tar.gz
delete: s3://s3-new-bash-course/file-backup-09-18-23_16_44_01.tar.gz
delete: s3://s3-new-bash-course/file-backup-09-18-23_16_42_01.tar.gz
remove_bucket: s3-new-bash-course


